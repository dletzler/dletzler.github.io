plot(iris.example$Sepal.Length, iris.example$Sepal.Width,
col = col.vec, pch = 16,
main = "Sepal Measurements of Iris Data")
legend("topleft", c("Setosa", "Versicolor", "Virginica"),
pch = 16, col = c("red", "green", "blue"), cex = .75)
missing.vector = c(41:50, 91:100, 141:150) #Inducing missing values on the Species
iris.example$Species[missing.vector] = NA  #vector for each category.
iris.example
col.vec[missing.vector] = "purple" #Creating a new color vector to
#mark the missing values.
plot(iris.example$Sepal.Length, iris.example$Sepal.Width,
col = col.vec, pch = 16,
main = "Sepal Measurements of Iris Data")
legend("topleft", c("Setosa", "Versicolor", "Virginica", "NA"),
pch = 16, col = c("red", "green", "blue", "purple"), cex = .75)
#Inspecting the Voronoi tesselation for the complete observations in the iris
#dataset.
library(deldir) #Load the Delaunay triangulation and Dirichelet tesselation library.
info = deldir(iris.example$Sepal.Length[-missing.vector],
iris.example$Sepal.Width[-missing.vector])
plot.tile.list(tile.list(info),
fillcol = col.vec[-missing.vector],
main = "Iris Voronoi Tessellation\nDecision Boundaries")
#Adding the observations that are missing species information.
points(iris.example$Sepal.Length[missing.vector],
iris.example$Sepal.Width[missing.vector],
pch = 16, col = "white")
points(iris.example$Sepal.Length[missing.vector],
iris.example$Sepal.Width[missing.vector],
pch = "?", cex = .66)
#Conducting a 1NN classification imputation.
iris.imputed1NN = kNN(iris.example, k = 1)
#Assessing the results by comparing to the truth known by the original dataset.
table(iris$Species, iris.imputed1NN$Species)
#Conducting a 12NN classification imputation based on the square root of n.
sqrt(nrow(iris.example))
iris.imputed12NN = kNN(iris.example, k = 12)
#Assessing the results by comparing to the truth known by the original dataset.
table(iris$Species, iris.imputed12NN$Species)
##################################################
#####Using Minkowski Distance Measures in KNN#####
##################################################
library(kknn) #Load the weighted knn library.
#Separating the complete and missing observations for use in the kknn() function.
complete = iris.example[-missing.vector, ]
missing = iris.example[missing.vector, -3]
iris.euclidean = kknn(Species ~ ., complete, missing, k = 12, distance = 2)
summary(iris.euclidean)
complete
missing
View(titanic.family.comp)
View(titanic.family.inc)
titanic.man<-kknn(age ~ ., titanic.family.comp, titanic.family.inc, k = 1, distance = 1)
summary(titanic.man)
str(titanic.man)
titanic.euc<-kknn(age ~ ., titanic.family.comp, titanic.family.inc, k = 1, distance = 2)
titanic.ten<-kknn(age ~ ., titanic.family.comp, titanic.family.inc, k = 1, distance = 1)#Answer 3.3c
class(titanic.man$CL)
class(titanic.man$fitted.values)
plot(density(titanic.man$fitted.values))
plot(density(titanic.man$fitted.values, titanic.euc$fitted.values))
titanic.age<-list(titanic.man$fitted.values, titanic.euc$fitted.values, titanic.ten$fitted.values, titanic.family.comp$age)
plot(density(titanic.man$fitted.values))
plot(density(titanic.euc$fitted.values))
plot(density(titanic.man$fitted.values))
lines(density(titanic.euc$fitted.values), col="red")
lines(density(titanic.ten$fitted.values), col ="blue")
lines(density(titanic.family.comp), col="green")
plot(density(titanic.man$fitted.values))
lines(density(titanic.euc$fitted.values), col="red")
lines(density(titanic.ten$fitted.values), col ="blue")
lines(density(titanic.family.comp$age), col="green")
plot(density(titanic.man$fitted.values), col="brown")
lines(density(titanic.euc$fitted.values), col="red")
lines(density(titanic.ten$fitted.values), col ="blue")
lines(density(titanic.family.comp$age), col="green")
titanic.ten<-kknn(age ~ ., titanic.family.comp, titanic.family.inc, k = 1, distance = 10)
plot(density(titanic.man$fitted.values), col="brown")
lines(density(titanic.euc$fitted.values), col="red")
lines(density(titanic.ten$fitted.values), col ="blue")
lines(density(titanic.family.comp$age), col="green")
titanic.hun<-kknn(age ~ ., titanic.family.comp, titanic.family.inc, k = 1, distance = 100)
lines(density(titanic.hun$fitted.values), col="yellow")
titanic.man2<-kknn(age ~ ., titanic.family.comp, titanic.family.inc, k = 36, distance = 1)#Answer 3.5a
titanic.euc2<-kknn(age ~ ., titanic.family.comp, titanic.family.inc, k = 36, distance = 2)#Answer 3.5b
titanic.ten2<-kknn(age ~ ., titanic.family.comp, titanic.family.inc, k = 36, distance = 10)#Answer 3.5c
plot(density(titanic.man2$fitted.values), col="brown")
lines(density(titanic.euc2$fitted.values), col="red")
lines(density(titanic.ten2$fitted.values), col ="blue")
lines(density(titanic.family.comp$age), col="green")
iris.example = iris[, c(1, 2, 5)] #For illustration purposes, pulling only the
#sepal measurements and the flower species.
#Throwing some small amount of noise on top of the data for illustration
#purposes; some observations are on top of each other.
set.seed(0)
iris.example$Sepal.Length = jitter(iris.example$Sepal.Length, factor = .5)
iris.example$Sepal.Width = jitter(iris.example$Sepal.Width, factor= .5)
col.vec = c(rep("red", 50), #Creating a color vector for plotting purposes.
rep("green", 50),
rep("blue", 50))
plot(iris.example$Sepal.Length, iris.example$Sepal.Width,
col = col.vec, pch = 16,
main = "Sepal Measurements of Iris Data")
legend("topleft", c("Setosa", "Versicolor", "Virginica"),
pch = 16, col = c("red", "green", "blue"), cex = .75)
missing.vector = c(41:50, 91:100, 141:150) #Inducing missing values on the Species
iris.example$Species[missing.vector] = NA  #vector for each category.
iris.example
col.vec[missing.vector] = "purple" #Creating a new color vector to
#mark the missing values.
plot(iris.example$Sepal.Length, iris.example$Sepal.Width,
col = col.vec, pch = 16,
main = "Sepal Measurements of Iris Data")
legend("topleft", c("Setosa", "Versicolor", "Virginica", "NA"),
pch = 16, col = c("red", "green", "blue", "purple"), cex = .75)
library(deldir) #Load the Delaunay triangulation and Dirichelet tesselation library.
info = deldir(iris.example$Sepal.Length[-missing.vector],
iris.example$Sepal.Width[-missing.vector])
plot.tile.list(tile.list(info),
fillcol = col.vec[-missing.vector],
main = "Iris Voronoi Tessellation\nDecision Boundaries")
install.packages(deldir)
install.packages('deldir')
points(iris.example$Sepal.Length[missing.vector],
iris.example$Sepal.Width[missing.vector],
pch = 16, col = "white")
points(iris.example$Sepal.Length[missing.vector],
iris.example$Sepal.Width[missing.vector],
pch = "?", cex = .66)
iris.imputed1NN = kNN(iris.example, k = 1)
??kNN
library(VIM)
iris.imputed1NN = kNN(iris.example, k = 1)
table(iris$Species, iris.imputed1NN$Species)
library(kknn)
sqrt(nrow(iris.example))
iris.imputed12NN = kNN(iris.example, k = 12)
table(iris$Species, iris.imputed12NN$Species)
complete = iris.example[-missing.vector, ]
missing = iris.example[missing.vector, -3]
plot.tile.list(tile.list(info),
fillcol = col.vec[-missing.vector],
main = "Iris Voronoi Tessellation\nDecision Boundaries")
library(deldir)
library(deldir) #Load the Delaunay triangulation and Dirichelet tesselation library.
info = deldir(iris.example$Sepal.Length[-missing.vector],
iris.example$Sepal.Width[-missing.vector])
plot.tile.list(tile.list(info),
fillcol = col.vec[-missing.vector],
main = "Iris Voronoi Tessellation\nDecision Boundaries")
points(iris.example$Sepal.Length[missing.vector],
iris.example$Sepal.Width[missing.vector],
pch = 16, col = "white")
points(iris.example$Sepal.Length[missing.vector],
iris.example$Sepal.Width[missing.vector],
pch = "?", cex = .66)
iris.imputed1NN = kNN(iris.example, k = 1)
#Assessing the results by comparing to the truth known by the original dataset.
table(iris$Species, iris.imputed1NN$Species)
sqrt(nrow(iris.example))
iris.imputed12NN = kNN(iris.example, k = 12)
#Assessing the results by comparing to the truth known by the original dataset.
table(iris$Species, iris.imputed12NN$Species)
?deldir::plot.tile.list
iris.euclidean = kknn(Species ~ ., complete, missing, k = 12, distance = 2)
summary(iris.euclidean)
iris.manhattan = kknn(Species ~ ., complete, missing, k = 12, distance = 1)
summary(iris.manhattan)
install.packages("MASS")
install.packages("MASS")
library('MASS')
scatter.smooth(cats$Hwt, cats$Bwt)
scatterplot(cats$Hwt, cats$Bwt)
?scatterplot
plot(cats$Hwt, cats$Bwt)
b1<-sum((cats$Bwt - mean(cats$Bwt))*(cats$Hwt - mean(cats$Hwt)))/sum((cats$Bwt - mean(cats$Bwt))^2)
b0<- mean(cats$Hwt) - b1*mean(cats$Bwt)
lines(y ~ b0 + b1*x)
lines(cats$Bwt ~ b0 + b1*cats$Hwt)
abline(b0, b1)
abline(b0, b1, lty=2)
plot(cats$Hwt, cats$Bwt)
abline(b0, b1, lty=2)
?abline
sum((cats$Bwt - mean(cats$Bwt))^2)
((cats$Bwt - mean(cats$Bwt))*(cats$Hwt - mean(cats$Hwt)))
sum((cats$Bwt - mean(cats$Bwt))*(cats$Hwt - mean(cats$Hwt)))
plot(cats$Bwt, cats$Hwt)
abline(b0, b1, lty=2)
?MASS::cats
rss.cats<_sum((cats$Hwt - b0 - b1*cats$Bwt)^2)
rss.cats<-sum((cats$Hwt - b0 - b1*cats$Bwt)^2)
tss.cats<-sum((cats$Hwt-mean(cats$Hwt))^2)
f<-tss.cats/(rss.cats/(nrow(cats)-2))
f
?f.test
f.test(cats$Bwt, cats$Bwt)
f(cats$Bwt, cats$Bwt)
?qf
boxplot(weight ~ group, PlantGrowth) #Answer 2.1: The values for all basic EDA were lower in tr1 than in ctrl, but higher in tr2 than ctrl.
PlantGrowth %>% group_by(group) %>% summarize(sd(weight))#Answer 2.2
ctrl = filter(PlantGrowth, group == "ctrl")
trt1 = filter(PlantGrowth, group == "trt1")
trt2 = filter(PlantGrowth, group == "trt2")
bartlett.test(list(ctrl$weight, trt1$weight, trt2$weight)) #Answer 2.2.a: p>0.2, not a significant difference in variance
library(dplyr)
library(datasets)
boxplot(weight ~ group, PlantGrowth) #Answer 2.1: The values for all basic EDA were lower in tr1 than in ctrl, but higher in tr2 than ctrl.
PlantGrowth %>% group_by(group) %>% summarize(sd(weight))#Answer 2.2
ctrl = filter(PlantGrowth, group == "ctrl")
trt1 = filter(PlantGrowth, group == "trt1")
trt2 = filter(PlantGrowth, group == "trt2")
bartlett.test(list(ctrl$weight, trt1$weight, trt2$weight)) #Answer 2.2.a
?bartlett.test
chisq.test(HairEyeColor[,1:2,2])$res
1-(rss.cats/tss.cats)
nrow(cats)
rss.cats/(nrow(cats)-2)^(0.5)
cats$Hwt(1:20)
cats$Hwt[1:20]
mean(cats$Hwt)
plot(cats$Bwt, cats$Hwt)
library('MASS')
plot(cats$Bwt, cats$Hwt)
abline(b0, b1)
?abline
help(cars)
cars #Investigating the cars dataset.
#Basic numerical EDA for cars dataset.
summary(cars) #Five number summaries.
sapply(cars, sd) #Standard deviations.
cor(cars) #Correlations.
#Basic graphical EDA for cars dataset.
hist(cars$speed, xlab = "Speed in MPH", main = "Histogram of Speed")
hist(cars$dist, xlab = "Distance in Feet", main = "Histogram of Distance")
plot(cars, xlab = "Speed in MPH", ylab = "Distance in Feet",
main = "Scatterplot of Cars Dataset")
#Manual calculation of simple linear regression coefficients.
beta1 = sum((cars$speed - mean(cars$speed)) * (cars$dist - mean(cars$dist))) /
sum((cars$speed - mean(cars$speed))^2)
beta0 = mean(cars$dist) - beta1*mean(cars$speed)
#Adding the least squares regression line to the plot.
abline(beta0, beta1, lty = 2)
#Calculating the residual values.
residuals = cars$dist - (beta0 + beta1*cars$speed)
#Note the sum of the residuals is 0.
sum(residuals)
segments(cars$speed, cars$dist,
cars$speed, (beta0 + beta1*cars$speed),
col = "red")
text(cars$speed - .5, cars$dist, round(residuals, 2), cex = 0.5)
?segments
segments(cats$Bwt, cats$Hwt, cats$Bwt, (b0 + b1*cats$Bwt))
segments(cats$Bwt, cats$Hwt, cats$Bwt, (b0 + b1*cats$Bwt), col="blue")
?t.test
cor.test(cats$Bwt, cats$Hwt)
cat.model<-lm(cats$Hwt ~ cats$Bwt)
confint(cat.model)
hist(cats$Bwt)
hist(cats$Hwt)
?hist
?curve
curve(dnorm)
curve(dnorm, mean=mean(cats$Bwt), sd=sd(cats$Bwt))
curve(dnorm, mean=mean(cats$Bwt), sd=sd(cats$Bwt), add=T)
warnings()
curve(dnorm, add=T)
curve(dnorm(cats$Bwt, mean=mean(cats$Bwt), sd=sd(cats$Bwt), add=T))
curve(dnorm, (cats$Bwt, mean=mean(cats$Bwt), sd=sd(cats$Bwt), add=T))
curve(dnorm(cats$Bwt, mean=mean(cats$Bwt), sd=sd(cats$Bwt), add=T))
curve(dnorm(x, mean=mean(cats$Bwt), sd=sd(cats$Bwt), add=T))
curve(dnorm(x, mean=mean(cats$Bwt), sd=sd(cats$Bwt)), add=T)
curve(dnorm(x, mean=mean(cats$Bwt), sd=sd(cats$Bwt)), add=T, lwd=2)
density(cats$Bwt)
plot(density(cats$Bwt))
curve(dnorm(x, mean=mean(cats$Bwt), sd=sd(cats$Bwt)), add=T, lwd=2)
hist(cats$Hwt)
curve(dnorm(x, mean=mean(cats$Hwt), sd=sd(cats$Hwt)), add=T)
plot(density(cats$Hwt)))
curve(dnorm(x, mean=mean(cats$Hwt), sd=sd(cats$Hwt)), add=T)
plot(density(cats$Hwt))
curve(dnorm(x, mean=mean(cats$Hwt), sd=sd(cats$Hwt)), add=T)
plot(model$fitted, model$residuals,
xlab = "Fitted Values", ylab = "Residual Values",
main = "Residual Plot for Cars Dataset")
abline(h = 0, lty = 2)
model = lm(dist ~ speed, data = cars) #Use the linear model function lm() to
#conduct the simple linear regression.
summary(model) #All the summary information for the model in question. Reports:
#-The five number summary of the residuals.
#-The coefficient estimates.
#-The coeffiient standard errors.
#-The t-test for significance of the coefficient estimates.
#-The p-values for the significance tests.
#-The level of significance.
#-The RSE and degrees of freedom for the model.
#-The coefficient of determination, R^2.
#-The overall model F-statistic and corresponding p-value.
#The equation of the model can be constructed from the output:
#Predicted Distance = -17.6 + (3.9)*Speed
#The interpretation for the slope coefficient: With a 1 MPH increase in car speed,
#the stopping distance, on average, increases by approximately 3.9 feet.
#The interpretation for the intercept coefficient: When a car's speed is 0 MPH,
#the stopping distance, on average, is -17.6 MPH. Theoretically, does this make
#sense? Why might this be the case?
#The residual standard error is about 15.38; this is an approximation of how much
#the residuas tend to deviate around the regression line.
#The coefficient of determination is about 0.65; approximately 65% of the variability
#in the distance variable is explained by the speed variable.
#The intercept, slope, and overall regression is extremely significant (p-values
#all below 0.05).
#Notice that the F-statistic value for the overall regression is the same as the
#square of the t-statistic value for the speed coefficient:
t.statistic = 9.464
f.statistic = 89.57
t.statistic^2
confint(model) #Creating 95% confidence intervals for the model coefficients.
plot(cars, xlab = "Speed in MPH", ylab = "Distance in Feet",
main = "Scatterplot of Cars Dataset")
abline(model, lty = 2)
plot(model$fitted, model$residuals,
xlab = "Fitted Values", ylab = "Residual Values",
main = "Residual Plot for Cars Dataset")
abline(h = 0, lty = 2)
qqnorm(model$residuals)
qqline(model$residuals)
summary(cat.model)
plot(cat.model$fitted.values, cat.model$residuals)
abline(h=0)
plot(cats$Bwt, cats$Hwt)
abline(b0, b1)
boxCox(cat.model)
library(car)
boxCox(cat.model)
predict(cat.model, interval="confidence")
predict(cat.model, interval="confidence", interval="prediction")
lines(predict(cat.model, interval="confidence"))[,2:3]
lines(predict(cat.model, interval="confidence"))[,2]
predict(cat.model, interval="confidence")
lines(predict(cat.model, interval="confidence")[2])
lines(predict(cat.model, interval="confidence")[,2])
lines(predict(cat.model, interval="confidence")[,3])
plot(cats$Bwt, cats$Hwt)
abline(b0, b1)
lines(predict(cat.model$fitted.values, interval="confidence")[,2], col="red")
?predict
summary(cat.model)
lines(cats$Hwt(predict(cat.model, interval="confidence")[,2], col="red"))
lines(cats$Hwt, predict(cat.model, interval="confidence")[,2], col="red")
lines(cats$Hwt, predict(cat.model, interval="confidence")[,3], col="red")
lines(cats, predict(cat.model, interval="confidence")[,2], col="red")
lines(cats, predict(cat.model, interval="confidence")[,3], col="red")
predict(cat.model, interval="confidence")[,2]
predict(cat.model, interval="confidence")[,3]
lines(cats$Hwt, predict(cat.model$fitted.values, interval="confidence")[,2], col="red")
lines(cats$Hwt, predict(cat.model$fitted.values, interval="confidence")[,3], col="red")
cat.model$fitted.values
lines(cats$Hwt, predict(cat.model, cats, interval="confidence")[,2], col="red")
lines(cats$Hwt, predict(cat.model, cats, interval="confidence")[,3], col="red")
lines(cats$Bwt, predict(cat.model, cats, interval="confidence")[,2], col="red")
lines(cats$Bwt, predict(cat.model, cats, interval="confidence")[,3], col="red")
plot(cats$Bwt, cats$Hwt)
abline(b0, b1)
lines(cats$Bwt, predict(cat.model, cats, interval="confidence")[,2], col="red")
lines(cats$Bwt, predict(cat.model, cats, interval="confidence")[,3], col="red")
lines(cats$Bwt, predict(cat.model, cats, interval="prediction")[,2], col="blue")
lines(cats$Bwt, predict(cat.model, cats, interval="prediction")[,3], col="blue")
boxCox(cat.model)
lambda = box.cat$x[which(box.cat$y == max(box.cat$y))]
box.cat<-boxCox(cat.model)#Answer 2.1
lambda = box.cat$x[which(box.cat$y == max(box.cat$y))]
cats2<-cats
cats2$Hwt<-log(cats2$Hwt)
cat.model.2<-lm(cats2$Hwt ~ cats2$Bwt)
plot(cat.model.2)
plot(cat.model.2)
qqnorm(cat.model)
qqnorm(cat.model$residuals)
qqline(cat.model$residuals)
plot(cats2$Bwt, cats2$Hwt)
cat.model$coefficients
abline(cat.model.2$coefficients)
summary(cat.model.2)
summary(cat.model)
plot(density(cats2$Bwt))
curve(dnorm(x, mean=mean(cats2$Bwt), sd=sd(cats2$Bwt)), add=T)
plot(density(cats2$Hwt))
curve(dnorm(x, mean=mean(cats2$Hwt), sd=sd(cats2$Hwt)), add=T)
plot(cat.model.2$fitted.values, cat.model.2$residuals)
abline(h=0)
qqnorm(cat.model.2$residuals)
qqline(cat.model.2$residuals)
box.cat<-boxCox(box.cat)
box.cat<-boxCox(cat.model.2)
cats3<-cats2
lambda = cat.model.2$x[which(cat.model.2$y == max(cat.model.2$y))]
lambda
box.cat<-boxCox(cat.model)
box.cat2<-boxCox(cat.model.2)
lambda = box.cat2$x[which(box.cat2$y == max(box.cat2$y))]
cats3$Hwt<-(cats2$Hwt^lambda - 1)/lambda
cat.model.3<-lm(cats3$Hwt ~ cats3$Bwt)
plot(cat.model.3)
plot(cats3$Bwt, cats3$Hwt)
abline(cat.model.3$coefficients)
summary(cat.model.3)
summary(cat.model.2)
summary(cat.model)
plot(density(cats3$Bwt))
curve(dnorm(x, mean=mean(cats3$Bwt), sd=sd(cats3$Bwt)), add=T)
plot(density(cats2$Hwt))
curve(dnorm(x, mean=mean(cats2$Hwt), sd=sd(cats2$Hwt)), add=T)
plot(cat.model.2$fitted.values, cat.model.2$residuals)
abline(h=0)
qqnorm(cat.model.2$residuals)
qqline(cat.model.2$residuals)
plot(density(cats2$Hwt))
curve(dnorm(x, mean=mean(cats2$Hwt), sd=sd(cats2$Hwt)), add=T)
setwd("c:/Users/David/Documents/NYCDSA/Project 2/jeopardy_1")
jeop_qs<-read.csv("Jeopardy.csv", stringsAsFactors=F, na.strings="NA")
View(jeop_qs)
jeop_qs<-jeop_qs[, c("Episode", "Date", "Round", "Order", "Category", "Value", "Clue", "Answer", "Right", "Wrong1", "Wrong2", "Wrong3", "Wrong4", "DailyDouble")]
j
jeop_qs<-jeop_qs[, c("Episode", "Date", "Round", "Order", "Category", "Value", "Clue", "Answer", "Right", "Wrong1", "Wrong2", "Wrong3", "Wrong4", "DailyDouble")]
jeop_qs$Value<-as.numeric(jeop_qs$Value)
jeop_qs$DailyDouble<-as.numeric(jeop_qs$DailyDouble)
jeop_qs$Date<-gsub(".*day, ", "", jeop_qs$Date)
jeop_qs$Date<-as.Date(jeop_qs$Date, "%B %d, %Y")
jeop_qs$Right[jeop_qs$Wrong1=="Triple Stumper"]<-"Triple Stumper"
jeop_qs$Right[jeop_qs$Wrong2=="Triple Stumper"]<-"Triple Stumper"
jeop_qs$Right[jeop_qs$Wrong3=="Triple Stumper"]<-"Triple Stumper"
jeop_qs$Right[jeop_qs$Wrong4=="Triple Stumper"]<-"Triple Stumper"
jeop_qs$Wrong1[jeop_qs$Wrong1=="Triple Stumper"]<-NA
jeop_qs$Wrong2[jeop_qs$Wrong2=="Triple Stumper"]<-NA
jeop_qs$Wrong3[jeop_qs$Wrong3=="Triple Stumper"]<-NA
jeop_qs$Wrong4[jeop_qs$Wrong4=="Triple Stumper"]<-NA
jeopqs$Wrong3[is.na(jeop_qs$Wrong3)]
jeop_qs$Wrong3[is.na(jeop_qs$Wrong3)]
jeop_qs$Wrong3[!is.na(jeop_qs$Wrong3)]
jeop_qs<-jeop_qs[,-13]
head(filter(jeop_qs, Clue=="Not asked"))
head(filter(jeop_qs, is.na(Clue)))
jeop_asked<-filter(jeop_qs, Clue!="Not asked")
jeop_qs[429,]
class(jeop_qs$Clue)
head(jeop_qs$Clue)
library(dplyr)
jeop_asked<-filter(jeop_qs, Clue!="Not asked")
total.round.qs<-jeop_qs %>% group_by(Round) %>% summarize(Total = n())
stumper<-jeop_qs %>% group_by(Round) %>% filter(Right=="Triple Stumper") %>% summarize(Total=n())
View(total.round.qs)
expected.value<-function(x){
if (x[9] == "Triple Stumper"){
a = 0
}
else{
a = as.numeric(x[6])
}
if (is.na(x[10])){
b = 0
}
else{
b = as.numeric(-x[6])
}
if (is.na(x[11])){
c = 0
}
else{
c = as.numeric(-x[6])
}
if (is.na(x[12])){
d = 0
}
else{
d = as.numeric(-x[6])
}
values<-as.numeric(c(a,b,c,d))
buzz<-as.numeric(values[values!=0])
if (length(buzz)>0){
ev <- sum(values)/length(buzz)
return (ev)
}
else{
return (0)
}
}
Expected.Value<-rep(0, nrow(jeop_asked))
for (i in 1:nrow(jeop_asked)){
Expected.Value[i]<-expected.value(jeop_asked[i,])
}
Expected.Value[1:10]
jeop_qs<-jeop_qs[order(jeop_qs$Date),]
jeop_asked$Expected.Value<-Expected.Value
jeop_asked<-jeop_asked[order(jeop_asked$Date),]
jeop_asked %>% group_by(Value) %>% group_by(Round) %>% summarize(Avg.Exp.Value=mean(Expected.Value))
jeop_asked %>% group_by(Value, Round) %>% summarize(Avg.Exp.Value=mean(Expected.Value))
value.exp<-jeop_asked %>% group_by(Value, Round) %>% summarize(Avg.Exp.Value=mean(Expected.Value))
View(value.exp)
value.exp2<-era2 %>% group_by(Value, Round) %>% summarize(Avg.Exp.Value=mean(Expected.Value))
era1<-filter(jeop_asked, Date < as.Date("November 26, 2001", "%B %d, %Y"))
era2<-filter(jeop_asked, Date >= as.Date("November 26, 2001", "%B %d, %Y"))
value.exp1<-era1 %>% group_by(Value, Round) %>% summarize(Avg.Exp.Value=mean(Expected.Value))
value.exp2<-era2 %>% group_by(Value, Round) %>% summarize(Avg.Exp.Value=mean(Expected.Value))
View(value.exp1)
View(value.exp2)
as.Date("November 26, 2001", "%B %d, %Y")
View(era2)
View(era1)
value.exp1<-value.exp1[c(6,11,14,17,19,10, 16, 20, 22, 24), ]
value.exp1<-era1 %>% group_by(Value, Round) %>% summarize(Avg.Exp.Value=mean(Expected.Value))
value.exp1<-value.exp1[c(6,11,15,17,19,10, 16, 20, 22, 24), ]
save.image("~/NYCDSA/Project 2/Sunday.RData")
